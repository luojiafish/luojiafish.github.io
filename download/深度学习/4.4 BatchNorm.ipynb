{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4091e015",
   "metadata": {},
   "source": [
    ">对当前 mini-batch 中的某一个 通道（channel），在这个 batch 里把这个通道的所有元素拿出来，\n",
    ">先算这一堆数的 均值和方差，\n",
    ">再用这两个统计量去把该通道上的所有元素做归一化，然后再乘以 γ、加上 β。\n",
    "\n",
    "**BN 层的计算流程固定是**\n",
    "\n",
    "$$\n",
    "x \\xrightarrow{\\text{用 batch 统计量标准化}} \\hat{x} \\xrightarrow{\\text{γ, β 仿射变换}} y\n",
    "$$\n",
    "\n",
    "也就是两步：\n",
    "\n",
    "---\n",
    "\n",
    "### 1. 硬操作（不可学习）：用当前 batch 的均值、方差做标准化\n",
    "\n",
    "$$\n",
    "\\hat{x} = \\frac{x - \\mu_B}{\\sqrt{\\sigma_B^2 + \\epsilon}}\n",
    "$$\n",
    "\n",
    "- $\\mu_B$：当前小批量的均值  \n",
    "- $\\sigma_B^2$：当前小批量的方差  \n",
    "- $\\epsilon$：很小的正数，防止除零  \n",
    "\n",
    "标准化后，$\\hat{x}$ 在当前 batch 上的均值接近 0、方差接近 1。\n",
    "\n",
    "---\n",
    "\n",
    "### 2. 软调整（可学习）：用 $\\gamma, \\beta$ 做按元素线性变换\n",
    "\n",
    "$$\n",
    "y = \\gamma \\hat{x} + \\beta\n",
    "$$\n",
    "\n",
    "- $\\gamma$：可学习的拉伸（scale）参数  \n",
    "- $\\beta$：可学习的平移（shift）参数  \n",
    "\n",
    "它们按元素作用在 $\\hat{x}$ 上，让网络自己决定：\n",
    "- 要不要放大/缩小某些通道；\n",
    "- 要不要平移均值；\n",
    "- 特殊情况下，$\\gamma,\\beta$ 还能让这一层**近似变成恒等映射（相当于几乎不归一化）**。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a7b725e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#全连接和卷积中归一化的实现\n",
    "def Batchnorm(X)\n",
    "    bs, channels, h, w = X.shape\n",
    "    X_hw = X.reshape(bs,channels,h*w)\n",
    "    mean, var = 0\n",
    "    for channel in range(channels)\n",
    "        miu = X_hw[:,channel,:].sum()/(bs*h*w).asscalar()\n",
    "        for \n",
    "        dera = (X_hw{=[[:,channel,:]]-miu)[:,channel,:].sum()/(bs*h*w).asscalar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92502233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([\n",
       "  [0.644912]\n",
       "  <NDArray 1 @cpu(0)>,\n",
       "  \n",
       "  [0.70823216]\n",
       "  <NDArray 1 @cpu(0)>,\n",
       "  \n",
       "  [0.5221201]\n",
       "  <NDArray 1 @cpu(0)>],\n",
       " [\n",
       "  [0.11155877]\n",
       "  <NDArray 1 @cpu(0)>,\n",
       "  \n",
       "  [0.04941921]\n",
       "  <NDArray 1 @cpu(0)>,\n",
       "  \n",
       "  [0.10902785]\n",
       "  <NDArray 1 @cpu(0)>])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import d2lzh as d2l\n",
    "from mxnet import autograd, gluon, init, nd\n",
    "from mxnet.gluon import nn\n",
    "# bs,C,H,W = X.shape\n",
    "# X_hw = X.reshape(bs,C,H*W)\n",
    "# mean, var = [],[]\n",
    "# for channel in range(C):\n",
    "#     miu = X_hw[:,channel,:].sum()/(bs*H*W)\n",
    "#     diff = X_hw[:, channel, :] - miu\n",
    "#     dera = (diff * diff).sum() / (bs * H * W)\n",
    "#     mean.append(miu)\n",
    "#     var.append(dera)\n",
    "# mean, var\n",
    "#X, X[:,1,:,:] 切片可行"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
