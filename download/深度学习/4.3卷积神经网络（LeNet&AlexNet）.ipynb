{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a2d4246",
   "metadata": {},
   "source": [
    "## LeNet\n",
    "> - 激活函数：给卷积层后面加一个非线性变换，让整个网络不再是简单的线性变换叠加，从而能拟合更复杂的函数,不然两层卷积等价于一个大卷积\n",
    "> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30766bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import d2lzh as d2l\n",
    "# import mxnet as mx\n",
    "# from mxnet import autograd, gluon, init, nd\n",
    "# from mxnet.gluon import loss as gloss, nn\n",
    "# import time\n",
    "\n",
    "# net = nn.Sequential()\n",
    "# net.add(nn.Conv2D(channels=6, kernel_size=5, activation='sigmoid'),\n",
    "#         nn.MaxPool2D(pool_size=2, strides=2),\n",
    "#         nn.Conv2D(channels=16, kernel_size=5, activation='sigmoid'),\n",
    "#         nn.MaxPool2D(pool_size=2, strides=2),\n",
    "#         # Dense会默认将(批量大小, 通道, 高, 宽)形状的输入转换成\n",
    "#         # (批量大小, 通道 * 高 * 宽)形状的输入\n",
    "#         nn.Dense(120, activation='sigmoid'),\n",
    "#         nn.Dense(84, activation='sigmoid'),\n",
    "#         nn.Dense(10))\n",
    "# X = nd.random.uniform(shape=(1, 1, 28, 28))\n",
    "# net.initialize()\n",
    "# for layer in net:\n",
    "#     X = layer(X)\n",
    "#     print(layer.name, 'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a02340a",
   "metadata": {},
   "source": [
    "## AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cf4447",
   "metadata": {},
   "outputs": [],
   "source": [
    "import d2lzh as d2l\n",
    "from mxnet import gluon, init, nd\n",
    "from mxnet.gluon import data as gdata, nn\n",
    "import os\n",
    "import sys\n",
    "\n",
    "net = nn.Sequential()\n",
    "# 使用较大的11 x 11窗口来捕获物体。同时使用步幅4来较大幅度减小输出高和宽。这里使用的输出通\n",
    "# 道数比LeNet中的也要大很多\n",
    "net.add(nn.Conv2D(96, kernel_size=11, strides=4, activation='relu'),\n",
    "        nn.MaxPool2D(pool_size=3, strides=2),\n",
    "        # 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数\n",
    "        nn.Conv2D(256, kernel_size=5, padding=2, activation='relu'),\n",
    "        nn.MaxPool2D(pool_size=3, strides=2),\n",
    "        # 连续3个卷积层，且使用更小的卷积窗口。除了最后的卷积层外，进一步增大了输出通道数。\n",
    "        # 前两个卷积层后不使用池化层来减小输入的高和宽\n",
    "        nn.Conv2D(384, kernel_size=3, padding=1, activation='relu'),\n",
    "        nn.Conv2D(384, kernel_size=3, padding=1, activation='relu'),\n",
    "        nn.Conv2D(256, kernel_size=3, padding=1, activation='relu'),\n",
    "        nn.MaxPool2D(pool_size=3, strides=2),\n",
    "        # 这里全连接层的输出个数比LeNet中的大数倍。使用丢弃层来缓解过拟合\n",
    "        # 但在 图像分类 里，最后一步往往就是把空间压掉（Flatten + Dense 或 GlobalAvgPool），得到一个全局的语义表示。\n",
    "        nn.Dense(4096, activation=\"relu\"), nn.Dropout(0.5),\n",
    "        nn.Dense(4096, activation=\"relu\"), nn.Dropout(0.5),\n",
    "        # 输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000\n",
    "        nn.Dense(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26bba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本函数已保存在d2lzh包中方便以后使用\n",
    "# root=os.path.join('~', '.mxnet', 'datasets', 'fashion-mnist')\n",
    "# 得到字符串Windows：\"~\\.mxnet\\datasets\\fashion-mnist\"\n",
    "# root = os.path.expanduser(root)\n",
    "# root = \"C:\\\\Users\\\\yangyuanhao\\\\.mxnet\\\\datasets\\\\fashion-mnist\"\n",
    "def load_data_fashion_mnist(batch_size, resize=None, root=os.path.join(\n",
    "        '~', '.mxnet', 'datasets', 'fashion-mnist')):\n",
    "    root = os.path.expanduser(root)  # 展开用户路径'~'\n",
    "    transformer = []\n",
    "    if resize:\n",
    "        transformer += [gdata.vision.transforms.Resize(resize)]\n",
    "    transformer += [gdata.vision.transforms.ToTensor()]\n",
    "    transformer = gdata.vision.transforms.Compose(transformer)\n",
    "    mnist_train = gdata.vision.FashionMNIST(root=root, train=True)\n",
    "    mnist_test = gdata.vision.FashionMNIST(root=root, train=False)\n",
    "    num_workers = 0 if sys.platform.startswith('win32') else 4\n",
    "    train_iter = gdata.DataLoader(\n",
    "        mnist_train.transform_first(transformer), batch_size, shuffle=True,\n",
    "        num_workers=num_workers)\n",
    "    test_iter = gdata.DataLoader(\n",
    "        mnist_test.transform_first(transformer), batch_size, shuffle=False,\n",
    "        num_workers=num_workers)\n",
    "    return train_iter, test_iter\n",
    "\n",
    "batch_size = 128\n",
    "# 如出现“out of memory”的报错信息，可减小batch_size或resize\n",
    "train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0e6f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, num_epochs, ctx = 0.01, 5, d2l.try_gpu()\n",
    "net.initialize(force_reinit=True, ctx=ctx, init=init.Xavier())\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': lr})\n",
    "d2l.train_ch5(net, train_iter, test_iter, batch_size, trainer, ctx, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dc6b2c",
   "metadata": {},
   "source": [
    "# 经典 CNN 模型学习速记\n",
    "\n",
    "> 学这些网络：**不要死记结构图**，只抓三点——「要解决什么问题」「用了什么新招」「这个招后来怎么被沿用」。\n",
    "\n",
    "---\n",
    "\n",
    "## 1. LeNet — CNN 起点\n",
    "\n",
    "- **要解决的问题**：用端到端神经网络替代手工特征做小图像分类。\n",
    "- **关键结构**：`卷积 + 池化 + 激活 + 全连接` 标准模板。\n",
    "- **记忆要点**：\n",
    "  - 局部感受野 + 权重共享 → 大幅减少参数。\n",
    "  - 后续所有 CNN 都是在这套框架上加强演化。\n",
    "\n",
    "---\n",
    "\n",
    "## 2. AlexNet — 更深 + 更好训练\n",
    "\n",
    "- **要解决的问题**：在大规模数据集（ImageNet）上训练更深网络。\n",
    "- **关键新招**：\n",
    "  - **ReLU**：非饱和激活，缓解梯度消失、加快训练。\n",
    "  - **Dropout**：主要放在全连接层，减轻过拟合。\n",
    "  - 更深网络 + 数据增强。\n",
    "- **记忆要点**：\n",
    "  - “深 + ReLU + Dropout + 大数据 + 数据增强” → 现代 CNN 训练基本套路的起点。\n",
    "\n",
    "---\n",
    "\n",
    "## 3. VGG — 小卷积核深堆叠\n",
    "\n",
    "- **要解决的问题**：在控制参数量的前提下继续加深网络。\n",
    "- **关键新招**：\n",
    "  - 全用 **3×3 卷积** 堆叠：\n",
    "    - 多个 3×3 ≈ 一个大卷积核，\n",
    "    - 参数更少、非线性层更多。\n",
    "  - 规则结构：`(3×3 conv × N) + max pool` 多次重复。\n",
    "- **记忆要点**：\n",
    "  - “小卷积核 + 深堆叠 + 规则 block” → 后续 ResNet / DenseNet 等 backbone 的基础设计风格。\n",
    "\n",
    "---\n",
    "\n",
    "## 4. NiN（Network in Network）— 卷积里的 MLP\n",
    "\n",
    "- **要解决的问题**：增强**每个空间位置**上的特征表达能力，而不只是线性卷积。\n",
    "- **关键新招**：\n",
    "  - **1×1 卷积 = 通道维上的全连接（MLP）**：\n",
    "    - 在每个像素位置对通道做非线性变换。\n",
    "  - 多层 1×1 堆叠 = 每个位置一个小 MLP。\n",
    "- **记忆要点**：\n",
    "  - 1×1 卷积 = **通道混合 + 非线性**。  \n",
    "  - 后续 Inception、通道注意力、残差中的“通道变换”都离不开它。\n",
    "\n",
    "---\n",
    "\n",
    "## 5. GoogLeNet / Inception — 多尺度 + 1×1 降维\n",
    "\n",
    "- **要解决的问题**：同时利用多尺度卷积核，又不让参数和计算爆炸。\n",
    "- **关键新招：Inception 模块**\n",
    "  - 多分支并联：\n",
    "    - 1×1 分支（基础特征）\n",
    "    - 3×3 分支\n",
    "    - 5×5 分支\n",
    "    - 池化 + 1×1 分支  \n",
    "    → 捕获多尺度特征。\n",
    "  - 在 3×3、5×5 前加 **1×1 卷积**：\n",
    "    - **降维**：先减通道数再做大卷积 → 减少参数与计算量。\n",
    "    - **加非线性**：多一层激活，提高表达能力。\n",
    "- **记忆要点**：\n",
    "  - 核心关键词：**“多尺度并联 + 1×1 降维 + 特征拼接（concat）”**。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea18eb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
